\chapter{Julia \& seus módulos} 
\label{ch:julia}

\begin{quotation}
    A programming language to heal the planet together.
    (Alan Edelman)
\end{quotation}

\begin{figure}[hbtp]
    \centering
    \caption{Logo da linguagem Julia}
    \includegraphics[scale = 0.6]{Figuras/julia-logo-color.pdf}
    \label{fig:julia-logo}
\end{figure}

Julia é uma linguagem de programação dinâmica, opcionalmente tipada, pré-compilada, generalista, de código livre\footnote{A Linguagem Julia é distribuída, quase integralmente, sob a MIT License, que permite a modificação, utilização e distribuição, seja comercial ou não, de qualquer parte do código, assim como das documentações associadas.} e de alto nível, criada por Jeff Bezanso, Stefan Karpinski, Viral B. Shah e Alan Edelman, em 2012, com o objetivo de minimizar o problema das duas linguagens (\emph{the two language problem}). É voltada para a programação científica, com capacidades de alta performance e sintaxe simples, similar à notação matemática usual. \cite{Sherrington}

Na aplicação do MEF, a linguagem se destaca por sua sintaxe semelhante a do MATLAB, que se mostra ideal na manipulação de matrizes e vetores, e por sua capacidade de processamento paralelo, que permite a otimização na construção e resolução de sistemas algébricos grandes. Além disso, o empacotamento oferecido pela linguagem, por meio do \emph{Pkg.jl}, fornece ferramentas de controle e versionamento, como também, a criação de módulos, uma forma eficiente de organizar e distribuir aplicações.

Este capítulo aborda brevemente alguns conceito dos seguintes tópicos, vinculados a pacotes, que são relevantes para a aplicação do MEF em Julia, e que foram explorados no desenvolvimento de PHILLIPO:

\begin{enumerate}
    \item matrizes esparsas, o \emph{SparseArrays.jl};
    \item processamento paralelo com \emph{Threads.jl} em estruturas de repetição;
\end{enumerate}


\section{Matrizes esparsa}

As matrizes esparsas desempenham um papel crucial em diversas áreas da computação científica, sendo particularmente relevantes no contexto do MEF quando se refere às matrizes de rigidez globais, que geralmente são grandes. Se $n$ é o número de nós e $g$ o número de graus de liberdade, a matriz de rigidez terá dimensão $ng \times ng$, que pode ser da ordem de milhares quando a malha é suficientemente refinada. No entanto, a maioria dos elementos da matriz de rigidez é nulo, pois cada nó está conectado apenas a um número limitado de outros nós, devido à conectividade dos elementos. Pode-se, então, definir essa matriz como esparsa, o que tem implicações importantes na sua armazenagem e manipulação \cite{LOGAN}.

Uma matriz esparsa é aquela em que a maioria dos elementos é igual a zero (em contraste com as matrizes densas, onde a maioria dos elementos é diferente de zero). Aqui são apresentadas duas formas de armazenamento de matrizes esparsas, e como elas podem ser utilizadas em Julia pelo módulo \emph{SparseArrays.jl}: COO e CSC.

O armazenamento de matrizes esparsas por coordenadas (COO) consiste em gravar apenas os valores não nulos em um conjunto de tuplas $(i, j, v)$, em que $i$ e $j$ são os índices de linha e coluna, respectivamente, e $v$ é o valor na posição correspondente. Todas outras posições são presumidas nulas \cite{sparse}. 

Uma matriz esparsa, por exemplo
\begin{equation}
    A = 
    \begin{bmatrix}
        3 & 0 & 0 & 13 \\
        0 & 5 & 0 & 0 \\
        0 & 0 & 0 & 11 \\
        0 & 7 & 0 & 9 \\
    \end{bmatrix},
    \label{eq:coo_matrix}
\end{equation}
pode ser armazenada no conjunto de tuplas
\begin{equation}
    A_{COO} = \{(1,1,5), (2,2,5), (3,3,0), (4,4,9), (1,4,13), (3,4,3), (4,2,7)\}.
    \label{eq:coo}
\end{equation}

Como tuplas não são comumente utilizadas em programação imperativa para armazenar um grande volume de dados, o conjunto é substituído por uma representação ordenada: um grupo de três vetores ($I$,$J$ e $V$). Para a matriz $A$, nessa forma

\begin{equation}
    I =  [1, 1, 2, 3, 4, 4], \qquad J = [1, 4, 2, 4, 2, 4], \quad V = [3, 13, 5, 11, 7, 9],
    \label{eq:coo_2}
\end{equation}
em que $I$ são os índices de linha, $J$ os índices de coluna e $V$ os valores não nulos.

Uma vantagem da utilização desse formato é a inserção de novos valores sobre posições não nulas. A inserção é realizada simplesmente concatenado mais uma posição nos vetores $I$, $J$ e $V$. Como é visto mais adiante, em outros formatos, como o CSC, essa operação requer mais alocações dependendo da posição nova a ser inserida.

O formato COO infelizmente não está presente no módulo \emph{SparseArrays.jl}, e por conta disso, foi implementado explicitamente em PHILLIPO, no módulo interno \emph{Matrices.jl}\footnote{Esse trecho do código é uma adaptação da implementação do formato COO em \emph{FEMSparse.jl}. Detalhes da implementação não fazem parte do escopo deste trabalho.}.

O formato CSC, por sua vez, já consiste em uma forma mais sofisticada, fazendo um mapeamento coluna por coluna. As entradas não nulas da matriz são organizados em ordem crescente de coluna e linha no vetor $V$, armazenando os índices de linha respectivos no vetor $I$. O vetor $J$ é substituído por um vetor $P$, que consiste nas posições do vetor $V$ que separam a armazenagem das colunas, e quando uma coluna só tem valores nulos a última posição da coluna não nula é repetida. Por convenção, ao final do vetor $P$ é concatenado a quantidade de entradas não nulas acrescida de um. A matriz $A$, nessa forma, se torna
\begin{equation}
    I = [1, 2, 4, 4, 1, 3], \qquad V = [3, 5, 7, 9, 13, 11], \quad P = [1,2,4,4,7].
    \label{eq:coo_3}
\end{equation}

O módulo \emph{SparseArrays.jl} implementa esse formato como padrão de matrizes esparsas, além de adicionar diversas otimizações matemáticas nas operações definidas pelo módulo \emph{LinearAlgebra.jl}, principalmente quando se trada de resolver grandes sistemas lineares, escolhendo a melhor rotina aplicável \footnote{Detalhes da implementação de rotinas otimizadas para matrizes esparsas não faz parte do escopo deste trabalho.}.

Vale também ressaltar que o módulo \emph{SparseArrays.jl} implementa as matrizes esparsas de modo que ainda sejam compatíveis com as operações convencionais, isto é, a sintaxe e funções definidas para matrizes densas (adição, multiplicação e seleção de entradas...) são aplicáveis também para matrizes esparsas, de forma que o usuário não precise se preocupar com a forma de armazenamento da matriz, e pode se ater apenas na resolução do problema em si.

\section{Processamento paralelo}

Computação paralela é um método de realizar múltiplos cálculos ou tarefas simultaneamente, utilizando vários processadores ou computadores. Essa abordagem tem o objetivo de aumentar a velocidade e eficiência do processamento, dividindo um problema maior em partes menores e independentes que podem ser resolvidas simultaneamente. Isso difere da computação sequencial tradicional, onde as tarefas são realizadas uma após a outra por um único processador. A computação paralela é frequentemente empregada em tarefas que podem ser divididas em subtarefas paralelas, como simulações científicas e análise de dados, para um aproveitamento maior da capacidade de processamento disponível \cite{sli}.

A linguagem Julia implementa suporte a quatro categorias de programação concorrente e paralela. Conforme a própria documentação da linguagem, são elas:

\begin{enumerate}
    \item Tarefas Assíncronas, ou Corotinas:
    As tarefas em Julia permitem a suspensão e retomada de computações para operações de entrada/saída, manipulação de eventos, processos produtor-consumidor e padrões semelhantes. As tarefas podem sincronizar por meio de operações como espera (wait) e obtenção (fetch), e se comunicam por meio de Canais. Embora estritamente não sejam computação paralela por si mesmas, Julia permite agendar tarefas em vários threads.\footnote{Esse conceito é similar as \emph{promises} em JavaScript.}

    \item Multi-threading:
    O suporte a multi-threading em Julia proporciona a capacidade de agendar tarefas simultaneamente em mais de um thread ou núcleo de CPU, compartilhando memória. Geralmente, essa é a maneira mais fácil de obter paralelismo em um PC ou em um único servidor com vários núcleos. O suporte a multi-threading em Julia é fornecido pelo módulo \emph{Threads.jl}.

    \item Computação Distribuída:
    A computação distribuída executa vários processos Julia com espaços de memória separados. Esses processos podem estar no mesmo computador ou em vários computadores. A biblioteca padrão Distribuída fornece a capacidade de execução remota de uma função Julia. Com esse bloco de construção básico, é possível criar várias abstrações de computação distribuída. Pacotes como DistributedArrays.jl são exemplos de tais abstrações. Por outro lado, pacotes como MPI.jl e Elemental.jl fornecem acesso ao ecossistema existente de bibliotecas MPI. O suporte a computação distribuída em Julia é fornecido pelo módulo \emph{Distributed.jl} \footnote{\emph{JuliaFEM.jl} utiliza desas abordagem para implementar o MEF de forma escalável.}.

    \item Computação em GPU:
    O compilador GPU em Julia proporciona a capacidade de executar código Julia nativamente em GPUs. Existe um ecossistema robusto de pacotes Julia voltados para GPUs. O site JuliaGPU.org fornece uma lista de capacidades, GPUs suportadas, pacotes relacionados e documentação.
\end{enumerate}


Neste trabalho foi aplicado um aspecto de Multi-threading diretamente, pelo o módulo \emph{Threads.jl}, para paralelizar a construção da matriz de rigidez global.

O módulo \emph{Threads.jl} fornece a possibilidade de executar um bloco de código em paralelo, por meio da macro \emph{@threads}. As macros são formas de metaprogramação implementadas em Julia, que servem como ferramentas para incluir e manipular o próprio código em tempo de execução\footnote{Isso é devido a homoiconicidade da linguagem.}. A macro \emph{@threads} é utilizada para transformar um bloco de repetição, leia-se loop, de assíncrono para síncrono, isto é, criando uma pilha de execuções formada pelas iterações do loop que são chamadas para as \emph{threads} conforme vão ficando disponíveis.

Uma \emph{thread}, ou linha de execução, é a menor unidade de processamento que pode ser programada em um sistema. É uma sequência de instruções que pode ser executada independentemente, compartilhando recursos com outras threads que pertencem ao mesmo processo. Em suma, é um fluxo de execução dentro de um processo\footnote{Processo aqui pode ser compreendido como a sessão Julia.}. \cite{ivob}

Conforme a sessão Julia é iniciada, uma \emph{thread} é criada para executar o código principal, e também são reservadas outras para executar tarefas síncronas, o que deve ser declarado explicitamente pelas flag \emph{-t}. Por padrão, a sessão nunca reserva mais de uma \emph{thread}.

